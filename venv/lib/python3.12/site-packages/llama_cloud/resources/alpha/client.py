# This file was auto-generated by Fern from our API Definition.

import typing
import urllib.parse
from json.decoder import JSONDecodeError

from ...core.api_error import ApiError
from ...core.client_wrapper import AsyncClientWrapper, SyncClientWrapper
from ...core.jsonable_encoder import jsonable_encoder
from ...core.remove_none_from_dict import remove_none_from_dict
from ...errors.unprocessable_entity_error import UnprocessableEntityError
from ...types.http_validation_error import HttpValidationError
from ...types.llama_parse_crop_box import LlamaParseCropBox
from ...types.llama_parse_input_options import LlamaParseInputOptions
from ...types.llama_parse_output_options import LlamaParseOutputOptions
from ...types.llama_parse_page_ranges import LlamaParsePageRanges
from ...types.llama_parse_processing_control import LlamaParseProcessingControl
from ...types.llama_parse_tier_options import LlamaParseTierOptions
from ...types.llama_parse_webhook_configuration import LlamaParseWebhookConfiguration
from ...types.markdown_result import MarkdownResult
from ...types.parsing_job import ParsingJob
from ...types.structured_result import StructuredResult
from ...types.text_result import TextResult

try:
    import pydantic
    if pydantic.__version__.startswith("1."):
        raise ImportError
    import pydantic.v1 as pydantic  # type: ignore
except ImportError:
    import pydantic  # type: ignore

# this is used as the default value for optional parameters
OMIT = typing.cast(typing.Any, ...)


class AlphaClient:
    def __init__(self, *, client_wrapper: SyncClientWrapper):
        self._client_wrapper = client_wrapper

    def upload_file_by_id_api_v_2_alpha_1_parse_post(
        self,
        *,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        client_name: typing.Optional[str] = OMIT,
        crop_box: typing.Optional[LlamaParseCropBox] = OMIT,
        disable_cache: typing.Optional[bool] = OMIT,
        file_id: str,
        input_options: typing.Optional[LlamaParseInputOptions] = OMIT,
        output_options: typing.Optional[LlamaParseOutputOptions] = OMIT,
        page_ranges: typing.Optional[LlamaParsePageRanges] = OMIT,
        parse_options: LlamaParseTierOptions,
        processing_control: typing.Optional[LlamaParseProcessingControl] = OMIT,
        webhook_configurations: typing.Optional[typing.List[LlamaParseWebhookConfiguration]] = OMIT,
    ) -> ParsingJob:
        """
        Parse an already uploaded file by file ID.

        Parameters:
            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].

            - client_name: typing.Optional[str].

            - crop_box: typing.Optional[LlamaParseCropBox]. Document crop box boundaries

            - disable_cache: typing.Optional[bool].

            - file_id: str. ID of an existing file in the project to parse

            - input_options: typing.Optional[LlamaParseInputOptions]. Input format-specific parsing options

            - output_options: typing.Optional[LlamaParseOutputOptions]. Output format and styling options

            - page_ranges: typing.Optional[LlamaParsePageRanges]. Page range selection options

            - parse_options: LlamaParseTierOptions. Parsing tier and related configuration options

            - processing_control: typing.Optional[LlamaParseProcessingControl]. Job processing control and failure handling

            - webhook_configurations: typing.Optional[typing.List[LlamaParseWebhookConfiguration]]. List of webhook configurations for notifications
        ---
        from llama_cloud import (LlamaParseAgenticOptions, LlamaParseCropBox,
                                 LlamaParseEmbeddedImagesOptions,
                                 LlamaParseExportPdfOptions, LlamaParseFastOptions,
                                 LlamaParseHtmlOptions, LlamaParseIgnoreOptions,
                                 LlamaParseInputOptions,
                                 LlamaParseJobFailureConditions,
                                 LlamaParseMarkdownOptions, LlamaParseOcrParameters,
                                 LlamaParseOutputOptions, LlamaParsePageRanges,
                                 LlamaParsePages, LlamaParsePdfOptions,
                                 LlamaParsePresentationOptions,
                                 LlamaParseProcessingControl,
                                 LlamaParseScreenshotsOptions,
                                 LlamaParseSpatialTextOptions,
                                 LlamaParseSpreadsheetOptions, LlamaParseTables,
                                 LlamaParseTablesAsSpreadsheetOptions,
                                 LlamaParseTierOptions, LlamaParseTierOptionsVersion,
                                 LlamaParseTimeouts, TierName)
        from llama_cloud.client import LlamaCloud

        client = LlamaCloud(token="YOUR_TOKEN", )
        client.alpha.upload_file_by_id_api_v_2_alpha_1_parse_post(crop_box=LlamaParseCropBox(), file_id="string", input_options=LlamaParseInputOptions(html=LlamaParseHtmlOptions(), pdf=LlamaParsePdfOptions(), presentation=LlamaParsePresentationOptions(), spreadsheet=LlamaParseSpreadsheetOptions(), ), output_options=LlamaParseOutputOptions(embedded_images=LlamaParseEmbeddedImagesOptions(), export_pdf=LlamaParseExportPdfOptions(), markdown=LlamaParseMarkdownOptions(pages=LlamaParsePages(), tables=LlamaParseTables(), ), screenshots=LlamaParseScreenshotsOptions(), spatial_text=LlamaParseSpatialTextOptions(pages=LlamaParsePages(), ), tables_as_spreadsheet=LlamaParseTablesAsSpreadsheetOptions(), ), page_ranges=LlamaParsePageRanges(), parse_options=LlamaParseTierOptions(agentic_options=LlamaParseAgenticOptions(ignore=LlamaParseIgnoreOptions(), ocr_parameters=LlamaParseOcrParameters(), ), fast_options=LlamaParseFastOptions(ignore=LlamaParseIgnoreOptions(), ocr_parameters=LlamaParseOcrParameters(), ), tier=TierName.FAST, version=LlamaParseTierOptionsVersion.2025_11_18, ), processing_control=LlamaParseProcessingControl(job_failure_conditions=LlamaParseJobFailureConditions(), timeouts=LlamaParseTimeouts(), ), )
        """
        _request: typing.Dict[str, typing.Any] = {"file_id": file_id, "parse_options": parse_options}
        if client_name is not OMIT:
            _request["client_name"] = client_name
        if crop_box is not OMIT:
            _request["crop_box"] = crop_box
        if disable_cache is not OMIT:
            _request["disable_cache"] = disable_cache
        if input_options is not OMIT:
            _request["input_options"] = input_options
        if output_options is not OMIT:
            _request["output_options"] = output_options
        if page_ranges is not OMIT:
            _request["page_ranges"] = page_ranges
        if processing_control is not OMIT:
            _request["processing_control"] = processing_control
        if webhook_configurations is not OMIT:
            _request["webhook_configurations"] = webhook_configurations
        _response = self._client_wrapper.httpx_client.request(
            "POST",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "api/v2alpha1/parse"),
            params=remove_none_from_dict({"project_id": project_id, "organization_id": organization_id}),
            json=jsonable_encoder(_request),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(ParsingJob, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def upload_file_base_64(
        self,
        *,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        base_64_file: str,
        client_name: typing.Optional[str] = OMIT,
        crop_box: typing.Optional[LlamaParseCropBox] = OMIT,
        disable_cache: typing.Optional[bool] = OMIT,
        filename: typing.Optional[str] = OMIT,
        input_options: typing.Optional[LlamaParseInputOptions] = OMIT,
        output_options: typing.Optional[LlamaParseOutputOptions] = OMIT,
        page_ranges: typing.Optional[LlamaParsePageRanges] = OMIT,
        parse_options: LlamaParseTierOptions,
        processing_control: typing.Optional[LlamaParseProcessingControl] = OMIT,
        webhook_configurations: typing.Optional[typing.List[LlamaParseWebhookConfiguration]] = OMIT,
    ) -> ParsingJob:
        """
        Upload a file using base64 encoded content in JSON request.

        Parameters:
            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].

            - base_64_file: str. Base64 encoded file content for parsing

            - client_name: typing.Optional[str].

            - crop_box: typing.Optional[LlamaParseCropBox]. Document crop box boundaries

            - disable_cache: typing.Optional[bool].

            - filename: typing.Optional[str].

            - input_options: typing.Optional[LlamaParseInputOptions]. Input format-specific parsing options

            - output_options: typing.Optional[LlamaParseOutputOptions]. Output format and styling options

            - page_ranges: typing.Optional[LlamaParsePageRanges]. Page range selection options

            - parse_options: LlamaParseTierOptions. Parsing tier and related configuration options

            - processing_control: typing.Optional[LlamaParseProcessingControl]. Job processing control and failure handling

            - webhook_configurations: typing.Optional[typing.List[LlamaParseWebhookConfiguration]]. List of webhook configurations for notifications
        ---
        from llama_cloud import (LlamaParseAgenticOptions, LlamaParseCropBox,
                                 LlamaParseEmbeddedImagesOptions,
                                 LlamaParseExportPdfOptions, LlamaParseFastOptions,
                                 LlamaParseHtmlOptions, LlamaParseIgnoreOptions,
                                 LlamaParseInputOptions,
                                 LlamaParseJobFailureConditions,
                                 LlamaParseMarkdownOptions, LlamaParseOcrParameters,
                                 LlamaParseOutputOptions, LlamaParsePageRanges,
                                 LlamaParsePages, LlamaParsePdfOptions,
                                 LlamaParsePresentationOptions,
                                 LlamaParseProcessingControl,
                                 LlamaParseScreenshotsOptions,
                                 LlamaParseSpatialTextOptions,
                                 LlamaParseSpreadsheetOptions, LlamaParseTables,
                                 LlamaParseTablesAsSpreadsheetOptions,
                                 LlamaParseTierOptions, LlamaParseTierOptionsVersion,
                                 LlamaParseTimeouts, TierName)
        from llama_cloud.client import LlamaCloud

        client = LlamaCloud(token="YOUR_TOKEN", )
        client.alpha.upload_file_base_64(base_64_file="string", crop_box=LlamaParseCropBox(), input_options=LlamaParseInputOptions(html=LlamaParseHtmlOptions(), pdf=LlamaParsePdfOptions(), presentation=LlamaParsePresentationOptions(), spreadsheet=LlamaParseSpreadsheetOptions(), ), output_options=LlamaParseOutputOptions(embedded_images=LlamaParseEmbeddedImagesOptions(), export_pdf=LlamaParseExportPdfOptions(), markdown=LlamaParseMarkdownOptions(pages=LlamaParsePages(), tables=LlamaParseTables(), ), screenshots=LlamaParseScreenshotsOptions(), spatial_text=LlamaParseSpatialTextOptions(pages=LlamaParsePages(), ), tables_as_spreadsheet=LlamaParseTablesAsSpreadsheetOptions(), ), page_ranges=LlamaParsePageRanges(), parse_options=LlamaParseTierOptions(agentic_options=LlamaParseAgenticOptions(ignore=LlamaParseIgnoreOptions(), ocr_parameters=LlamaParseOcrParameters(), ), fast_options=LlamaParseFastOptions(ignore=LlamaParseIgnoreOptions(), ocr_parameters=LlamaParseOcrParameters(), ), tier=TierName.FAST, version=LlamaParseTierOptionsVersion.2025_11_18, ), processing_control=LlamaParseProcessingControl(job_failure_conditions=LlamaParseJobFailureConditions(), timeouts=LlamaParseTimeouts(), ), )
        """
        _request: typing.Dict[str, typing.Any] = {"base64_file": base_64_file, "parse_options": parse_options}
        if client_name is not OMIT:
            _request["client_name"] = client_name
        if crop_box is not OMIT:
            _request["crop_box"] = crop_box
        if disable_cache is not OMIT:
            _request["disable_cache"] = disable_cache
        if filename is not OMIT:
            _request["filename"] = filename
        if input_options is not OMIT:
            _request["input_options"] = input_options
        if output_options is not OMIT:
            _request["output_options"] = output_options
        if page_ranges is not OMIT:
            _request["page_ranges"] = page_ranges
        if processing_control is not OMIT:
            _request["processing_control"] = processing_control
        if webhook_configurations is not OMIT:
            _request["webhook_configurations"] = webhook_configurations
        _response = self._client_wrapper.httpx_client.request(
            "POST",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "api/v2alpha1/parse/base64"),
            params=remove_none_from_dict({"project_id": project_id, "organization_id": organization_id}),
            json=jsonable_encoder(_request),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(ParsingJob, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def get_markdown_template(self, job_id: str, *, organization_id: typing.Optional[str] = None) -> MarkdownResult:
        """
        Get a job's markdown result by id

        Parameters:
            - job_id: str.

            - organization_id: typing.Optional[str].
        ---
        from llama_cloud.client import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
        )
        client.alpha.get_markdown_template(
            job_id="string",
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(
                f"{self._client_wrapper.get_base_url()}/", f"api/v2alpha1/parse/job/{job_id}/result/markdown"
            ),
            params=remove_none_from_dict({"organization_id": organization_id}),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(MarkdownResult, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def get_structured_template(self, job_id: str, *, organization_id: typing.Optional[str] = None) -> StructuredResult:
        """
        Get a job's structured result by id

        Parameters:
            - job_id: str.

            - organization_id: typing.Optional[str].
        ---
        from llama_cloud.client import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
        )
        client.alpha.get_structured_template(
            job_id="string",
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(
                f"{self._client_wrapper.get_base_url()}/", f"api/v2alpha1/parse/job/{job_id}/result/structured"
            ),
            params=remove_none_from_dict({"organization_id": organization_id}),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(StructuredResult, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def get_text_template(self, job_id: str, *, organization_id: typing.Optional[str] = None) -> TextResult:
        """
        Get a job's text result by id

        Parameters:
            - job_id: str.

            - organization_id: typing.Optional[str].
        ---
        from llama_cloud.client import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
        )
        client.alpha.get_text_template(
            job_id="string",
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(
                f"{self._client_wrapper.get_base_url()}/", f"api/v2alpha1/parse/job/{job_id}/result/text"
            ),
            params=remove_none_from_dict({"organization_id": organization_id}),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(TextResult, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def upload_file_multipart(
        self, *, project_id: typing.Optional[str] = None, organization_id: typing.Optional[str] = None
    ) -> ParsingJob:
        """
        Parameters:
            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].
        ---
        from llama_cloud.client import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
        )
        client.alpha.upload_file_multipart()
        """
        _response = self._client_wrapper.httpx_client.request(
            "POST",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "api/v2alpha1/parse/upload"),
            params=remove_none_from_dict({"project_id": project_id, "organization_id": organization_id}),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(ParsingJob, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def upload_file_by_url(
        self,
        *,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        client_name: typing.Optional[str] = OMIT,
        crop_box: typing.Optional[LlamaParseCropBox] = OMIT,
        disable_cache: typing.Optional[bool] = OMIT,
        http_proxy: typing.Optional[str] = OMIT,
        input_options: typing.Optional[LlamaParseInputOptions] = OMIT,
        output_options: typing.Optional[LlamaParseOutputOptions] = OMIT,
        page_ranges: typing.Optional[LlamaParsePageRanges] = OMIT,
        parse_options: LlamaParseTierOptions,
        processing_control: typing.Optional[LlamaParseProcessingControl] = OMIT,
        source_url: str,
        webhook_configurations: typing.Optional[typing.List[LlamaParseWebhookConfiguration]] = OMIT,
    ) -> ParsingJob:
        """
        Parse a document from a URL.

        Parameters:
            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].

            - client_name: typing.Optional[str].

            - crop_box: typing.Optional[LlamaParseCropBox]. Document crop box boundaries

            - disable_cache: typing.Optional[bool].

            - http_proxy: typing.Optional[str].

            - input_options: typing.Optional[LlamaParseInputOptions]. Input format-specific parsing options

            - output_options: typing.Optional[LlamaParseOutputOptions]. Output format and styling options

            - page_ranges: typing.Optional[LlamaParsePageRanges]. Page range selection options

            - parse_options: LlamaParseTierOptions. Parsing tier and related configuration options

            - processing_control: typing.Optional[LlamaParseProcessingControl]. Job processing control and failure handling

            - source_url: str. Source URL to fetch document from

            - webhook_configurations: typing.Optional[typing.List[LlamaParseWebhookConfiguration]]. List of webhook configurations for notifications
        ---
        from llama_cloud import (LlamaParseAgenticOptions, LlamaParseCropBox,
                                 LlamaParseEmbeddedImagesOptions,
                                 LlamaParseExportPdfOptions, LlamaParseFastOptions,
                                 LlamaParseHtmlOptions, LlamaParseIgnoreOptions,
                                 LlamaParseInputOptions,
                                 LlamaParseJobFailureConditions,
                                 LlamaParseMarkdownOptions, LlamaParseOcrParameters,
                                 LlamaParseOutputOptions, LlamaParsePageRanges,
                                 LlamaParsePages, LlamaParsePdfOptions,
                                 LlamaParsePresentationOptions,
                                 LlamaParseProcessingControl,
                                 LlamaParseScreenshotsOptions,
                                 LlamaParseSpatialTextOptions,
                                 LlamaParseSpreadsheetOptions, LlamaParseTables,
                                 LlamaParseTablesAsSpreadsheetOptions,
                                 LlamaParseTierOptions, LlamaParseTierOptionsVersion,
                                 LlamaParseTimeouts, TierName)
        from llama_cloud.client import LlamaCloud

        client = LlamaCloud(token="YOUR_TOKEN", )
        client.alpha.upload_file_by_url(crop_box=LlamaParseCropBox(), input_options=LlamaParseInputOptions(html=LlamaParseHtmlOptions(), pdf=LlamaParsePdfOptions(), presentation=LlamaParsePresentationOptions(), spreadsheet=LlamaParseSpreadsheetOptions(), ), output_options=LlamaParseOutputOptions(embedded_images=LlamaParseEmbeddedImagesOptions(), export_pdf=LlamaParseExportPdfOptions(), markdown=LlamaParseMarkdownOptions(pages=LlamaParsePages(), tables=LlamaParseTables(), ), screenshots=LlamaParseScreenshotsOptions(), spatial_text=LlamaParseSpatialTextOptions(pages=LlamaParsePages(), ), tables_as_spreadsheet=LlamaParseTablesAsSpreadsheetOptions(), ), page_ranges=LlamaParsePageRanges(), parse_options=LlamaParseTierOptions(agentic_options=LlamaParseAgenticOptions(ignore=LlamaParseIgnoreOptions(), ocr_parameters=LlamaParseOcrParameters(), ), fast_options=LlamaParseFastOptions(ignore=LlamaParseIgnoreOptions(), ocr_parameters=LlamaParseOcrParameters(), ), tier=TierName.FAST, version=LlamaParseTierOptionsVersion.2025_11_18, ), processing_control=LlamaParseProcessingControl(job_failure_conditions=LlamaParseJobFailureConditions(), timeouts=LlamaParseTimeouts(), ), source_url="string", )
        """
        _request: typing.Dict[str, typing.Any] = {"parse_options": parse_options, "source_url": source_url}
        if client_name is not OMIT:
            _request["client_name"] = client_name
        if crop_box is not OMIT:
            _request["crop_box"] = crop_box
        if disable_cache is not OMIT:
            _request["disable_cache"] = disable_cache
        if http_proxy is not OMIT:
            _request["http_proxy"] = http_proxy
        if input_options is not OMIT:
            _request["input_options"] = input_options
        if output_options is not OMIT:
            _request["output_options"] = output_options
        if page_ranges is not OMIT:
            _request["page_ranges"] = page_ranges
        if processing_control is not OMIT:
            _request["processing_control"] = processing_control
        if webhook_configurations is not OMIT:
            _request["webhook_configurations"] = webhook_configurations
        _response = self._client_wrapper.httpx_client.request(
            "POST",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "api/v2alpha1/parse/url"),
            params=remove_none_from_dict({"project_id": project_id, "organization_id": organization_id}),
            json=jsonable_encoder(_request),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(ParsingJob, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)


class AsyncAlphaClient:
    def __init__(self, *, client_wrapper: AsyncClientWrapper):
        self._client_wrapper = client_wrapper

    async def upload_file_by_id_api_v_2_alpha_1_parse_post(
        self,
        *,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        client_name: typing.Optional[str] = OMIT,
        crop_box: typing.Optional[LlamaParseCropBox] = OMIT,
        disable_cache: typing.Optional[bool] = OMIT,
        file_id: str,
        input_options: typing.Optional[LlamaParseInputOptions] = OMIT,
        output_options: typing.Optional[LlamaParseOutputOptions] = OMIT,
        page_ranges: typing.Optional[LlamaParsePageRanges] = OMIT,
        parse_options: LlamaParseTierOptions,
        processing_control: typing.Optional[LlamaParseProcessingControl] = OMIT,
        webhook_configurations: typing.Optional[typing.List[LlamaParseWebhookConfiguration]] = OMIT,
    ) -> ParsingJob:
        """
        Parse an already uploaded file by file ID.

        Parameters:
            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].

            - client_name: typing.Optional[str].

            - crop_box: typing.Optional[LlamaParseCropBox]. Document crop box boundaries

            - disable_cache: typing.Optional[bool].

            - file_id: str. ID of an existing file in the project to parse

            - input_options: typing.Optional[LlamaParseInputOptions]. Input format-specific parsing options

            - output_options: typing.Optional[LlamaParseOutputOptions]. Output format and styling options

            - page_ranges: typing.Optional[LlamaParsePageRanges]. Page range selection options

            - parse_options: LlamaParseTierOptions. Parsing tier and related configuration options

            - processing_control: typing.Optional[LlamaParseProcessingControl]. Job processing control and failure handling

            - webhook_configurations: typing.Optional[typing.List[LlamaParseWebhookConfiguration]]. List of webhook configurations for notifications
        ---
        from llama_cloud import (LlamaParseAgenticOptions, LlamaParseCropBox,
                                 LlamaParseEmbeddedImagesOptions,
                                 LlamaParseExportPdfOptions, LlamaParseFastOptions,
                                 LlamaParseHtmlOptions, LlamaParseIgnoreOptions,
                                 LlamaParseInputOptions,
                                 LlamaParseJobFailureConditions,
                                 LlamaParseMarkdownOptions, LlamaParseOcrParameters,
                                 LlamaParseOutputOptions, LlamaParsePageRanges,
                                 LlamaParsePages, LlamaParsePdfOptions,
                                 LlamaParsePresentationOptions,
                                 LlamaParseProcessingControl,
                                 LlamaParseScreenshotsOptions,
                                 LlamaParseSpatialTextOptions,
                                 LlamaParseSpreadsheetOptions, LlamaParseTables,
                                 LlamaParseTablesAsSpreadsheetOptions,
                                 LlamaParseTierOptions, LlamaParseTierOptionsVersion,
                                 LlamaParseTimeouts, TierName)
        from llama_cloud.client import AsyncLlamaCloud

        client = AsyncLlamaCloud(token="YOUR_TOKEN", )
        await client.alpha.upload_file_by_id_api_v_2_alpha_1_parse_post(crop_box=LlamaParseCropBox(), file_id="string", input_options=LlamaParseInputOptions(html=LlamaParseHtmlOptions(), pdf=LlamaParsePdfOptions(), presentation=LlamaParsePresentationOptions(), spreadsheet=LlamaParseSpreadsheetOptions(), ), output_options=LlamaParseOutputOptions(embedded_images=LlamaParseEmbeddedImagesOptions(), export_pdf=LlamaParseExportPdfOptions(), markdown=LlamaParseMarkdownOptions(pages=LlamaParsePages(), tables=LlamaParseTables(), ), screenshots=LlamaParseScreenshotsOptions(), spatial_text=LlamaParseSpatialTextOptions(pages=LlamaParsePages(), ), tables_as_spreadsheet=LlamaParseTablesAsSpreadsheetOptions(), ), page_ranges=LlamaParsePageRanges(), parse_options=LlamaParseTierOptions(agentic_options=LlamaParseAgenticOptions(ignore=LlamaParseIgnoreOptions(), ocr_parameters=LlamaParseOcrParameters(), ), fast_options=LlamaParseFastOptions(ignore=LlamaParseIgnoreOptions(), ocr_parameters=LlamaParseOcrParameters(), ), tier=TierName.FAST, version=LlamaParseTierOptionsVersion.2025_11_18, ), processing_control=LlamaParseProcessingControl(job_failure_conditions=LlamaParseJobFailureConditions(), timeouts=LlamaParseTimeouts(), ), )
        """
        _request: typing.Dict[str, typing.Any] = {"file_id": file_id, "parse_options": parse_options}
        if client_name is not OMIT:
            _request["client_name"] = client_name
        if crop_box is not OMIT:
            _request["crop_box"] = crop_box
        if disable_cache is not OMIT:
            _request["disable_cache"] = disable_cache
        if input_options is not OMIT:
            _request["input_options"] = input_options
        if output_options is not OMIT:
            _request["output_options"] = output_options
        if page_ranges is not OMIT:
            _request["page_ranges"] = page_ranges
        if processing_control is not OMIT:
            _request["processing_control"] = processing_control
        if webhook_configurations is not OMIT:
            _request["webhook_configurations"] = webhook_configurations
        _response = await self._client_wrapper.httpx_client.request(
            "POST",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "api/v2alpha1/parse"),
            params=remove_none_from_dict({"project_id": project_id, "organization_id": organization_id}),
            json=jsonable_encoder(_request),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(ParsingJob, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def upload_file_base_64(
        self,
        *,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        base_64_file: str,
        client_name: typing.Optional[str] = OMIT,
        crop_box: typing.Optional[LlamaParseCropBox] = OMIT,
        disable_cache: typing.Optional[bool] = OMIT,
        filename: typing.Optional[str] = OMIT,
        input_options: typing.Optional[LlamaParseInputOptions] = OMIT,
        output_options: typing.Optional[LlamaParseOutputOptions] = OMIT,
        page_ranges: typing.Optional[LlamaParsePageRanges] = OMIT,
        parse_options: LlamaParseTierOptions,
        processing_control: typing.Optional[LlamaParseProcessingControl] = OMIT,
        webhook_configurations: typing.Optional[typing.List[LlamaParseWebhookConfiguration]] = OMIT,
    ) -> ParsingJob:
        """
        Upload a file using base64 encoded content in JSON request.

        Parameters:
            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].

            - base_64_file: str. Base64 encoded file content for parsing

            - client_name: typing.Optional[str].

            - crop_box: typing.Optional[LlamaParseCropBox]. Document crop box boundaries

            - disable_cache: typing.Optional[bool].

            - filename: typing.Optional[str].

            - input_options: typing.Optional[LlamaParseInputOptions]. Input format-specific parsing options

            - output_options: typing.Optional[LlamaParseOutputOptions]. Output format and styling options

            - page_ranges: typing.Optional[LlamaParsePageRanges]. Page range selection options

            - parse_options: LlamaParseTierOptions. Parsing tier and related configuration options

            - processing_control: typing.Optional[LlamaParseProcessingControl]. Job processing control and failure handling

            - webhook_configurations: typing.Optional[typing.List[LlamaParseWebhookConfiguration]]. List of webhook configurations for notifications
        ---
        from llama_cloud import (LlamaParseAgenticOptions, LlamaParseCropBox,
                                 LlamaParseEmbeddedImagesOptions,
                                 LlamaParseExportPdfOptions, LlamaParseFastOptions,
                                 LlamaParseHtmlOptions, LlamaParseIgnoreOptions,
                                 LlamaParseInputOptions,
                                 LlamaParseJobFailureConditions,
                                 LlamaParseMarkdownOptions, LlamaParseOcrParameters,
                                 LlamaParseOutputOptions, LlamaParsePageRanges,
                                 LlamaParsePages, LlamaParsePdfOptions,
                                 LlamaParsePresentationOptions,
                                 LlamaParseProcessingControl,
                                 LlamaParseScreenshotsOptions,
                                 LlamaParseSpatialTextOptions,
                                 LlamaParseSpreadsheetOptions, LlamaParseTables,
                                 LlamaParseTablesAsSpreadsheetOptions,
                                 LlamaParseTierOptions, LlamaParseTierOptionsVersion,
                                 LlamaParseTimeouts, TierName)
        from llama_cloud.client import AsyncLlamaCloud

        client = AsyncLlamaCloud(token="YOUR_TOKEN", )
        await client.alpha.upload_file_base_64(base_64_file="string", crop_box=LlamaParseCropBox(), input_options=LlamaParseInputOptions(html=LlamaParseHtmlOptions(), pdf=LlamaParsePdfOptions(), presentation=LlamaParsePresentationOptions(), spreadsheet=LlamaParseSpreadsheetOptions(), ), output_options=LlamaParseOutputOptions(embedded_images=LlamaParseEmbeddedImagesOptions(), export_pdf=LlamaParseExportPdfOptions(), markdown=LlamaParseMarkdownOptions(pages=LlamaParsePages(), tables=LlamaParseTables(), ), screenshots=LlamaParseScreenshotsOptions(), spatial_text=LlamaParseSpatialTextOptions(pages=LlamaParsePages(), ), tables_as_spreadsheet=LlamaParseTablesAsSpreadsheetOptions(), ), page_ranges=LlamaParsePageRanges(), parse_options=LlamaParseTierOptions(agentic_options=LlamaParseAgenticOptions(ignore=LlamaParseIgnoreOptions(), ocr_parameters=LlamaParseOcrParameters(), ), fast_options=LlamaParseFastOptions(ignore=LlamaParseIgnoreOptions(), ocr_parameters=LlamaParseOcrParameters(), ), tier=TierName.FAST, version=LlamaParseTierOptionsVersion.2025_11_18, ), processing_control=LlamaParseProcessingControl(job_failure_conditions=LlamaParseJobFailureConditions(), timeouts=LlamaParseTimeouts(), ), )
        """
        _request: typing.Dict[str, typing.Any] = {"base64_file": base_64_file, "parse_options": parse_options}
        if client_name is not OMIT:
            _request["client_name"] = client_name
        if crop_box is not OMIT:
            _request["crop_box"] = crop_box
        if disable_cache is not OMIT:
            _request["disable_cache"] = disable_cache
        if filename is not OMIT:
            _request["filename"] = filename
        if input_options is not OMIT:
            _request["input_options"] = input_options
        if output_options is not OMIT:
            _request["output_options"] = output_options
        if page_ranges is not OMIT:
            _request["page_ranges"] = page_ranges
        if processing_control is not OMIT:
            _request["processing_control"] = processing_control
        if webhook_configurations is not OMIT:
            _request["webhook_configurations"] = webhook_configurations
        _response = await self._client_wrapper.httpx_client.request(
            "POST",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "api/v2alpha1/parse/base64"),
            params=remove_none_from_dict({"project_id": project_id, "organization_id": organization_id}),
            json=jsonable_encoder(_request),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(ParsingJob, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def get_markdown_template(
        self, job_id: str, *, organization_id: typing.Optional[str] = None
    ) -> MarkdownResult:
        """
        Get a job's markdown result by id

        Parameters:
            - job_id: str.

            - organization_id: typing.Optional[str].
        ---
        from llama_cloud.client import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
        )
        await client.alpha.get_markdown_template(
            job_id="string",
        )
        """
        _response = await self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(
                f"{self._client_wrapper.get_base_url()}/", f"api/v2alpha1/parse/job/{job_id}/result/markdown"
            ),
            params=remove_none_from_dict({"organization_id": organization_id}),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(MarkdownResult, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def get_structured_template(
        self, job_id: str, *, organization_id: typing.Optional[str] = None
    ) -> StructuredResult:
        """
        Get a job's structured result by id

        Parameters:
            - job_id: str.

            - organization_id: typing.Optional[str].
        ---
        from llama_cloud.client import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
        )
        await client.alpha.get_structured_template(
            job_id="string",
        )
        """
        _response = await self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(
                f"{self._client_wrapper.get_base_url()}/", f"api/v2alpha1/parse/job/{job_id}/result/structured"
            ),
            params=remove_none_from_dict({"organization_id": organization_id}),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(StructuredResult, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def get_text_template(self, job_id: str, *, organization_id: typing.Optional[str] = None) -> TextResult:
        """
        Get a job's text result by id

        Parameters:
            - job_id: str.

            - organization_id: typing.Optional[str].
        ---
        from llama_cloud.client import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
        )
        await client.alpha.get_text_template(
            job_id="string",
        )
        """
        _response = await self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(
                f"{self._client_wrapper.get_base_url()}/", f"api/v2alpha1/parse/job/{job_id}/result/text"
            ),
            params=remove_none_from_dict({"organization_id": organization_id}),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(TextResult, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def upload_file_multipart(
        self, *, project_id: typing.Optional[str] = None, organization_id: typing.Optional[str] = None
    ) -> ParsingJob:
        """
        Parameters:
            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].
        ---
        from llama_cloud.client import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
        )
        await client.alpha.upload_file_multipart()
        """
        _response = await self._client_wrapper.httpx_client.request(
            "POST",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "api/v2alpha1/parse/upload"),
            params=remove_none_from_dict({"project_id": project_id, "organization_id": organization_id}),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(ParsingJob, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def upload_file_by_url(
        self,
        *,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        client_name: typing.Optional[str] = OMIT,
        crop_box: typing.Optional[LlamaParseCropBox] = OMIT,
        disable_cache: typing.Optional[bool] = OMIT,
        http_proxy: typing.Optional[str] = OMIT,
        input_options: typing.Optional[LlamaParseInputOptions] = OMIT,
        output_options: typing.Optional[LlamaParseOutputOptions] = OMIT,
        page_ranges: typing.Optional[LlamaParsePageRanges] = OMIT,
        parse_options: LlamaParseTierOptions,
        processing_control: typing.Optional[LlamaParseProcessingControl] = OMIT,
        source_url: str,
        webhook_configurations: typing.Optional[typing.List[LlamaParseWebhookConfiguration]] = OMIT,
    ) -> ParsingJob:
        """
        Parse a document from a URL.

        Parameters:
            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].

            - client_name: typing.Optional[str].

            - crop_box: typing.Optional[LlamaParseCropBox]. Document crop box boundaries

            - disable_cache: typing.Optional[bool].

            - http_proxy: typing.Optional[str].

            - input_options: typing.Optional[LlamaParseInputOptions]. Input format-specific parsing options

            - output_options: typing.Optional[LlamaParseOutputOptions]. Output format and styling options

            - page_ranges: typing.Optional[LlamaParsePageRanges]. Page range selection options

            - parse_options: LlamaParseTierOptions. Parsing tier and related configuration options

            - processing_control: typing.Optional[LlamaParseProcessingControl]. Job processing control and failure handling

            - source_url: str. Source URL to fetch document from

            - webhook_configurations: typing.Optional[typing.List[LlamaParseWebhookConfiguration]]. List of webhook configurations for notifications
        ---
        from llama_cloud import (LlamaParseAgenticOptions, LlamaParseCropBox,
                                 LlamaParseEmbeddedImagesOptions,
                                 LlamaParseExportPdfOptions, LlamaParseFastOptions,
                                 LlamaParseHtmlOptions, LlamaParseIgnoreOptions,
                                 LlamaParseInputOptions,
                                 LlamaParseJobFailureConditions,
                                 LlamaParseMarkdownOptions, LlamaParseOcrParameters,
                                 LlamaParseOutputOptions, LlamaParsePageRanges,
                                 LlamaParsePages, LlamaParsePdfOptions,
                                 LlamaParsePresentationOptions,
                                 LlamaParseProcessingControl,
                                 LlamaParseScreenshotsOptions,
                                 LlamaParseSpatialTextOptions,
                                 LlamaParseSpreadsheetOptions, LlamaParseTables,
                                 LlamaParseTablesAsSpreadsheetOptions,
                                 LlamaParseTierOptions, LlamaParseTierOptionsVersion,
                                 LlamaParseTimeouts, TierName)
        from llama_cloud.client import AsyncLlamaCloud

        client = AsyncLlamaCloud(token="YOUR_TOKEN", )
        await client.alpha.upload_file_by_url(crop_box=LlamaParseCropBox(), input_options=LlamaParseInputOptions(html=LlamaParseHtmlOptions(), pdf=LlamaParsePdfOptions(), presentation=LlamaParsePresentationOptions(), spreadsheet=LlamaParseSpreadsheetOptions(), ), output_options=LlamaParseOutputOptions(embedded_images=LlamaParseEmbeddedImagesOptions(), export_pdf=LlamaParseExportPdfOptions(), markdown=LlamaParseMarkdownOptions(pages=LlamaParsePages(), tables=LlamaParseTables(), ), screenshots=LlamaParseScreenshotsOptions(), spatial_text=LlamaParseSpatialTextOptions(pages=LlamaParsePages(), ), tables_as_spreadsheet=LlamaParseTablesAsSpreadsheetOptions(), ), page_ranges=LlamaParsePageRanges(), parse_options=LlamaParseTierOptions(agentic_options=LlamaParseAgenticOptions(ignore=LlamaParseIgnoreOptions(), ocr_parameters=LlamaParseOcrParameters(), ), fast_options=LlamaParseFastOptions(ignore=LlamaParseIgnoreOptions(), ocr_parameters=LlamaParseOcrParameters(), ), tier=TierName.FAST, version=LlamaParseTierOptionsVersion.2025_11_18, ), processing_control=LlamaParseProcessingControl(job_failure_conditions=LlamaParseJobFailureConditions(), timeouts=LlamaParseTimeouts(), ), source_url="string", )
        """
        _request: typing.Dict[str, typing.Any] = {"parse_options": parse_options, "source_url": source_url}
        if client_name is not OMIT:
            _request["client_name"] = client_name
        if crop_box is not OMIT:
            _request["crop_box"] = crop_box
        if disable_cache is not OMIT:
            _request["disable_cache"] = disable_cache
        if http_proxy is not OMIT:
            _request["http_proxy"] = http_proxy
        if input_options is not OMIT:
            _request["input_options"] = input_options
        if output_options is not OMIT:
            _request["output_options"] = output_options
        if page_ranges is not OMIT:
            _request["page_ranges"] = page_ranges
        if processing_control is not OMIT:
            _request["processing_control"] = processing_control
        if webhook_configurations is not OMIT:
            _request["webhook_configurations"] = webhook_configurations
        _response = await self._client_wrapper.httpx_client.request(
            "POST",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "api/v2alpha1/parse/url"),
            params=remove_none_from_dict({"project_id": project_id, "organization_id": organization_id}),
            json=jsonable_encoder(_request),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(ParsingJob, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)
